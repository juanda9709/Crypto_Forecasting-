hyperparams:
  tsfresh-rolled-data: {}                      # Etapas del proceso
  tsextractFeatures: {}
  basic-scaler: {}
  #baseline-preprocessing: {}
regressor:
  KnnRegressor:                      #Modelo e hiperparámetros del modelo
    n_neighbors: 10


data:
  filepath: train.csv  #indica donde están los datos
  days: 1           #indica cuantos registros en días se van a tomar del dataset (iniciando desde el último día hacia atrás) 
  test_size: 0.1       #indica el tamaño del test
  crypto: 1            # INDICE ID CRIPTOS:
                          #     0 -> Binance Coin       7 -> Ethereum Classic
                          #     1 -> Bitcoin            8 -> IOTA
                          #     2 -> Bitcoin Cash       9 -> Litecoin
                          #     3 -> Cardano            10 -> Maker
                          #     4 -> Dogecoin           11 -> Monero
                          #     5 -> EOS.IO             12 -> Stellar
                          #     6 -> Ethereum           13 -> TRON

metrics:
  - name: symmetric mean absolute percentage error    #indica la metrica y lo relacionado con ella
    params: {}                                        # hiperparámetros de la métrica

  - name: bias   
    params: {}     

  - name: mean absolute percentage error
    params: {}

  - name: pearson correlation coefficient
    params: {}

search:                       # Cuando se utiliza GridSearch para buscar hiperparámetros
  jobs: -1
  preprocessing:
    tsfresh-rolled-data: {}
    tsextractFeatures: {}
    basic-scaler: {}
  regressor: 
    LGBMRegressor: {}
  regressor_grid:
    LGBMRegressor:                      #Modelo e hiperparámetros del modelo
      boosting_type: ['gbdt', 'dart']
      n_estimators:  [ 100, 125, 130, 140, 150]
      learning_rate: [0.005, 0.01, 0.1]
      #num_leaves: [16, 20, 28]
      #max_bin: [255, 510]
      #reg_alpha: [1, 1.2]
      #subsample: [0.5, 0.7, 0.75]
    # metric: ['minkowski', 'euclidean', 'manhattan', 'chebyshev']
    #  weights: ['uniform', 'distance']
      #num_leaves: [200, 400, 500]
     # reg_alpha: [1.1, 1.2, 1.3]
  forecaster_grid:
    lags: [3, 5,10,30,50]


export:
  output_dir: ./models          # Modelos que se implementaron  

reports:
  dir: ./reports                # Reportes con todo los del proceso de entrenamiento


      # LGBMRegressor:                      #Modelo e hiperparámetros del modelo
      # n_estimators: [100, 300, 500]
      # max_depth: [15,20,25]
      # num_leaves: [50, 100, 200]
      # reg_alpha: [1.1, 1.2, 1.3]
      # min_split_gain: [0.3, 0.4]
      # subsample: [0.7, 0.8, 0.9]